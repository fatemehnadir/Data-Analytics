{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "712d60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac1ccb4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hiclass in c:\\users\\rayan\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\rayan\\anaconda3\\lib\\site-packages (from hiclass) (2.7.1)\n",
      "Requirement already satisfied: numpy<1.24 in c:\\users\\rayan\\anaconda3\\lib\\site-packages (from hiclass) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rayan\\anaconda3\\lib\\site-packages (from hiclass) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\rayan\\anaconda3\\lib\\site-packages (from scikit-learn->hiclass) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\rayan\\anaconda3\\lib\\site-packages (from scikit-learn->hiclass) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rayan\\anaconda3\\lib\\site-packages (from scikit-learn->hiclass) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install hiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f781b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from hiclass import LocalClassifierPerNode\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6877cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(model, meth, fset, x, y):\n",
    "\n",
    "    if meth == \"ovr\":\n",
    "        clf = OneVsRestClassifier(model)\n",
    "        print(\"Classification on {} feature set with OneVsRest\\n\".format(fset))\n",
    "    elif meth == \"ovo\":\n",
    "        clf = OneVsOneClassifier(model)\n",
    "        print(\"Classification Regression on {} feature set with OneVsOne\\n\".format(fset))\n",
    "    else:\n",
    "        clf = model\n",
    "        print(\"Classification on {} feature set\\n\".format(fset))\n",
    "        \n",
    "    scoring = { 'accuracy' : make_scorer(accuracy_score), \n",
    "                'precision' : make_scorer(precision_score, average='macro', zero_division=0),\n",
    "                'recall' : make_scorer(recall_score, average='macro', zero_division=0), \n",
    "                'f1_score' : make_scorer(f1_score, average='macro', zero_division=0)}    \n",
    "    kfold = KFold(n_splits=10)\n",
    "\n",
    "    results = cross_validate(   estimator=clf,\n",
    "                                X=x,\n",
    "                                y=y,\n",
    "                                cv=kfold,\n",
    "                                scoring=scoring)\n",
    "    print(f\"Accuracy :{np.mean(results['test_accuracy'])}\")\n",
    "    print('-'*70)\n",
    "    print(f\"Precision :{np.mean(results['test_precision'])}\")\n",
    "    print('-'*70)\n",
    "    print(f\"Recall :{np.mean(results['test_recall'])}\")\n",
    "    print('-'*70)\n",
    "    print(f\"F1 score :{np.mean(results['test_f1_score'])}\")\n",
    "    print('-'*70)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f26d4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing all the model objects with default parameters\n",
    "model_1 = LogisticRegression()\n",
    "model_2 = XGBClassifier()\n",
    "model_3 = RandomForestClassifier()\n",
    "model_4 = DecisionTreeClassifier()\n",
    "\n",
    "# Making the final model using voting classifier\n",
    "final_model = VotingClassifier(\n",
    "    estimators=[('lr', model_1), ('xgb', model_2), ('rf', model_3), ('tree', model_4)], voting='hard')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e68de17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression on first feature set\n",
      "\n",
      "Accuracy :0.371\n",
      "----------------------------------------------------------------------\n",
      "Precision :0.23811891827396042\n",
      "----------------------------------------------------------------------\n",
      "Recall :0.21617401749836346\n",
      "----------------------------------------------------------------------\n",
      "F1 score :0.1906089062660763\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "voting_clf = show_metrics(final_model, \"\", \"first\", X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "498e50e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression on first feature set\n",
      "\n",
      "Accuracy :0.39\n",
      "----------------------------------------------------------------------\n",
      "Precision :0.2734948547332607\n",
      "----------------------------------------------------------------------\n",
      "Recall :0.24211594776468393\n",
      "----------------------------------------------------------------------\n",
      "F1 score :0.20876660529587543\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=30, max_depth=None,\n",
    "     min_samples_split=2, random_state=0)\n",
    "\n",
    "random_forest_cls = show_metrics(clf, \"\", \"first\", X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4cfc371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression on first feature set\n",
      "\n",
      "Accuracy :0.385\n",
      "----------------------------------------------------------------------\n",
      "Precision :0.27934733512653687\n",
      "----------------------------------------------------------------------\n",
      "Recall :0.24224579225861492\n",
      "----------------------------------------------------------------------\n",
      "F1 score :0.20468951912187924\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=30, max_depth=None,\n",
    "     min_samples_split=2, random_state=0)\n",
    "\n",
    "extra_trees_clf = show_metrics(clf, \"\", \"first\", X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9ab9efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression on first feature set\n",
      "\n",
      "Accuracy :0.29300000000000004\n",
      "----------------------------------------------------------------------\n",
      "Precision :0.19420398166284303\n",
      "----------------------------------------------------------------------\n",
      "Recall :0.2095582648289625\n",
      "----------------------------------------------------------------------\n",
      "F1 score :0.17191564219728256\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "ada_boost_cls = show_metrics(clf, \"\", \"first\", X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "249d5877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression on first feature set\n",
      "\n",
      "Accuracy :0.406\n",
      "----------------------------------------------------------------------\n",
      "Precision :0.3212613198063612\n",
      "----------------------------------------------------------------------\n",
      "Recall :0.2934929236695795\n",
      "----------------------------------------------------------------------\n",
      "F1 score :0.2828101336583594\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "classifier = LocalClassifierPerNode(local_classifier=rf)\n",
    "\n",
    "hiclass_clf = show_metrics(classifier, \"\", \"first\", X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
